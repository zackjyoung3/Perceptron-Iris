For this project, I wanted to create a simple perceptron and visualize the process through which the training is performed. I found that the iris training set was linearly seperable for the first 100 training examples. Thus, I load the data in from the UCI ML db, restrict the data to that which I know to be linearly seperable and then encode the class labels. I further convert the data to numpy mx so that operations are optimized. I then have a method that creates a graphic dusplay that affirms that the data is indeed linearly seperable. I then train the perceptron model on the data and return the weight vector that resulted from training and along the way append the number of misclassified examples in each epoch to a list that is returned. After that, I invoke a method that allows the user to visualize the manner in which misclassifications varies over epochs. After doing that testing on remaining attributes yielded perfect accuracy.

Update: I decided to also implement a perceptron that utilized 10-fold cross validation to observe the manner in which different training and test sets would take longer or shorter to obtain the hyperplane that seperated examples in the form of th trained weight vector.

Second Update: Wanted to see how it would perform on a dataset where the class labels were not linearly seperable. Used the breast cancer dataset and created a new method to encode categorical attributes. Ran for many epochs to observe the manner in which the weight vector values never stabilize.

Third Update: Expanded the project so that the 10-fold cross validation didn't have accuracy as the sole performance measure. Created confusion matrices and implemented methods to compute the Micro-Precision, Micro-Recall, Micro-F1, Macro-Precision, Macro-Recall and Macro-F1 along with the accuracy in order to gain a nuanced comprehension of the performance of perceptron on datasets
